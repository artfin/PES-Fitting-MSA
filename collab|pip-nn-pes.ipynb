{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f1d0ea53",
      "metadata": {
        "id": "f1d0ea53"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_env():\n",
        "  !rm -fv *.py\n",
        "  !rm -fv *.py*\n",
        "  !rm -fv *.pl\n",
        "  !rm -rfv H2-H2O/\n",
        "  !rm -rfv src/"
      ],
      "metadata": {
        "id": "ISeGGrbcZN-V"
      },
      "id": "ISeGGrbcZN-V",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_env()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMCPsxL0Zc3Y",
        "outputId": "93f62d5f-0838-4c92-9011-520a009775ae"
      },
      "id": "HMCPsxL0Zc3Y",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "removed 'adahessian.py'\n",
            "removed 'dataset.py'\n",
            "removed 'genpip.py'\n",
            "removed 'model.py'\n",
            "removed 'dataset.py.1'\n",
            "removed 'model.py.1'\n",
            "removed 'postmsa.pl'\n",
            "removed 'H2-H2O/MOL_2_2_1_3.BAS'\n",
            "removed 'H2-H2O/MOL_2_2_1_3.POLY'\n",
            "removed 'H2-H2O/MOL_2_2_1_3.MONO'\n",
            "removed 'H2-H2O/MOL_2_2_1_3.FOC'\n",
            "removed 'H2-H2O/points.dat'\n",
            "removed 'H2-H2O/basis_2_2_1_3.f90'\n",
            "removed 'H2-H2O/basis_2_2_1_3.so'\n",
            "removed 'H2-H2O/MOL_2_2_1_3.MAP'\n",
            "removed directory 'H2-H2O/'\n",
            "removed 'src/polynomial.o'\n",
            "removed 'src/Makefile'\n",
            "removed 'src/molecule_simple.hh'\n",
            "removed 'src/msa.o'\n",
            "removed 'src/poly_basis.cpp'\n",
            "removed 'src/utility.hh'\n",
            "removed 'src/msa'\n",
            "removed 'src/polynomial.hh'\n",
            "removed 'src/monomial.hh'\n",
            "removed 'src/monomial.o'\n",
            "removed 'src/monomial.cpp'\n",
            "removed 'src/polynomial.cpp'\n",
            "removed 'src/msa.cpp'\n",
            "removed directory 'src/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "ch = logging.StreamHandler()\n",
        "formatter = logging.Formatter('[%(levelname)s] %(message)s')\n",
        "ch.setFormatter(formatter)\n",
        "logger.addHandler(ch)"
      ],
      "metadata": {
        "id": "B7r8CVqOYX_a"
      },
      "id": "B7r8CVqOYX_a",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -v src/\n",
        "\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/Makefile\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/molecule_simple.hh\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/monomial.cpp\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/monomial.hh\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/msa.cpp\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/poly_basis.cpp\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/polynomial.cpp\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/polynomial.hh\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/src/utility.hh\n",
        "\n",
        "!mv -v Makefile src/\n",
        "!mv -v molecule_simple.hh src/\n",
        "!mv -v monomial.cpp src/\n",
        "!mv -v monomial.hh src/\n",
        "!mv -v msa.cpp src/\n",
        "!mv -v poly_basis.cpp src/\n",
        "!mv -v polynomial.cpp src/\n",
        "!mv -v polynomial.hh src/\n",
        "!mv -v utility.hh src/\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "zaQcJSwlW1tn"
      },
      "id": "zaQcJSwlW1tn",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/H2-H2O/points.zip\n",
        "\n",
        "!mkdir -v H2-H2O\n",
        "\n",
        "with ZipFile('points.zip', 'r') as f:\n",
        "  f.extractall()\n",
        "\n",
        "!mv -v points.dat H2-H2O/\n",
        "!rm -vf points.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeMSbEqHfC_R",
        "outputId": "324be025-aea9-4f1b-b033-d72f5c544c9b"
      },
      "id": "EeMSbEqHfC_R",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-31 17:36:02--  https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/H2-H2O/points.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2794987 (2.7M) [application/zip]\n",
            "Saving to: ‘points.zip’\n",
            "\n",
            "\rpoints.zip            0%[                    ]       0  --.-KB/s               \rpoints.zip          100%[===================>]   2.67M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-01-31 17:36:02 (109 MB/s) - ‘points.zip’ saved [2794987/2794987]\n",
            "\n",
            "mkdir: created directory 'H2-H2O'\n",
            "renamed 'points.dat' -> 'H2-H2O/points.dat'\n",
            "removed 'points.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/genpip.py\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/postmsa.pl\n",
        "\n",
        "from genpip import build_lib\n",
        "from genpip import run_msa\n",
        "from genpip import compile_dlib\n",
        "\n",
        "logging.info(\"building MSA library...\\n\")\n",
        "build_lib()\n",
        "\n",
        "order = \"3\"\n",
        "symmetry = \"2 2 1\"\n",
        "wdir = \"H2-H2O\"\n",
        "config_fname = \"points.dat\"\n",
        "\n",
        "run_msa(order, symmetry, wdir)\n",
        "\n",
        "!perl postmsa.pl H2-H2O 3 2 2 1\n",
        "!gfortran -fPIC -shared H2-H2O/basis_2_2_1_3.f90 -o H2-H2O/basis_2_2_1_3.so"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4idLeFCX621",
        "outputId": "f4f2f6aa-3ab8-44c4-b6dd-9ff4dc957fe0"
      },
      "id": "c4idLeFCX621",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-31 17:36:07--  https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/genpip.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3159 (3.1K) [text/plain]\n",
            "Saving to: ‘genpip.py’\n",
            "\n",
            "genpip.py           100%[===================>]   3.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-31 17:36:07 (57.7 MB/s) - ‘genpip.py’ saved [3159/3159]\n",
            "\n",
            "--2022-01-31 17:36:07--  https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/postmsa.pl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6936 (6.8K) [text/plain]\n",
            "Saving to: ‘postmsa.pl’\n",
            "\n",
            "postmsa.pl          100%[===================>]   6.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-31 17:36:07 (78.7 MB/s) - ‘postmsa.pl’ saved [6936/6936]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] building MSA library...\n",
            "\n",
            "[INFO] g++ -O2 -Wall -c msa.cpp \n",
            "g++ -O2 -Wall -c monomial.cpp \n",
            "g++ -O2 -Wall -c polynomial.cpp \n",
            "g++ -O2 -Wall -o msa msa.o monomial.o polynomial.o\n",
            "[INFO] cmd: ./src/msa 3 2 2 1\n",
            "[INFO] \n",
            "[INFO] PIP basis files successfully generated.\n",
            "[INFO] renamed 'MOL_2_2_1_3.BAS' -> 'H2-H2O/MOL_2_2_1_3.BAS'\n",
            "[INFO] renamed 'MOL_2_2_1_3.FOC' -> 'H2-H2O/MOL_2_2_1_3.FOC'\n",
            "[INFO] renamed 'MOL_2_2_1_3.MAP' -> 'H2-H2O/MOL_2_2_1_3.MAP'\n",
            "[INFO] renamed 'MOL_2_2_1_3.MONO' -> 'H2-H2O/MOL_2_2_1_3.MONO'\n",
            "[INFO] renamed 'MOL_2_2_1_3.POLY' -> 'H2-H2O/MOL_2_2_1_3.POLY'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# original github repo\n",
        "# https://github.com/amirgholami/adahessian\n",
        "# \n",
        "# lessw2020 update\n",
        "# https://github.com/lessw2020/Best-Deep-Learning-Optimizers/tree/master/adahessian\n",
        "\n",
        "#!wget https://raw.githubusercontent.com/lessw2020/Best-Deep-Learning-Optimizers/master/adahessian/adahessian.py\n",
        "#from adahessian import Adahessian, get_params_grad\n",
        "\n",
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "\n",
        "# imported from utils to avoid needing two imports... @lessw2020\n",
        "def get_params_grad(model):\n",
        "    \"\"\"\n",
        "    get model parameters and corresponding gradients\n",
        "    \"\"\"\n",
        "    params = []\n",
        "    grads = []\n",
        "    for param in model.parameters():\n",
        "        if not param.requires_grad:\n",
        "            continue\n",
        "        params.append(param)\n",
        "        grads.append(0. if param.grad is None else param.grad + 0.)\n",
        "    return params, grads\n",
        "\n",
        "class Adahessian(Optimizer):\n",
        "    \"\"\"Implements Adahessian algorithm.\n",
        "    It has been proposed in `ADAHESSIAN: An Adaptive Second OrderOptimizer for Machine Learning`.\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float, optional): learning rate (default: 0.15)\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing\n",
        "            running averages of gradient and its square (default: (0.9, 0.999))\n",
        "        eps (float, optional): term added to the denominator to improve\n",
        "            numerical stability (default: 1e-4)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        hessian_power (float, optional): Hessian power (default: 1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=0.15, betas=(0.9, 0.999), eps=1e-4,\n",
        "                 weight_decay=0, hessian_power=1):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\n",
        "                \"Invalid beta parameter at index 0: {}\".format(\n",
        "                    betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\n",
        "                \"Invalid beta parameter at index 1: {}\".format(\n",
        "                    betas[1]))\n",
        "        if not 0.0 <= hessian_power <= 1.0:\n",
        "            raise ValueError(\"Invalid Hessian power value: {}\".format(hessian_power))\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, hessian_power=hessian_power)\n",
        "\n",
        "        super(Adahessian, self).__init__(params, defaults)\n",
        "\n",
        "    def get_trace(self, gradsH):\n",
        "        \"\"\"\n",
        "        compute the Hessian vector product with a random vector v, at the current gradient point,\n",
        "        i.e., compute the gradient of <gradsH,v>.\n",
        "        :param gradsH: a list of torch variables\n",
        "        :return: a list of torch tensors\n",
        "        \"\"\"\n",
        "\n",
        "        params = self.param_groups[0]['params']\n",
        "\n",
        "        v = [torch.randint_like(p, high=2) for p in params]\n",
        "        for v_i in v:\n",
        "            v_i[v_i == 0] = -1\n",
        "        hvs = torch.autograd.grad(\n",
        "            gradsH,\n",
        "            params,\n",
        "            grad_outputs=v,\n",
        "            only_inputs=True,\n",
        "            retain_graph=True)\n",
        "\n",
        "        hutchinson_trace = []\n",
        "        for hv, vi in zip(hvs, v):\n",
        "            param_size = hv.size()\n",
        "            if len(param_size) <= 2:  # for 0/1/2D tensor\n",
        "                tmp_output = torch.abs(hv * vi)\n",
        "                hutchinson_trace.append(tmp_output) # Hessian diagonal block size is 1 here.\n",
        "            elif len(param_size) == 4:  # Conv kernel\n",
        "                tmp_output = torch.abs(torch.sum(torch.abs(\n",
        "                    hv * vi), dim=[2, 3], keepdim=True)) / vi[0, 1].numel() # Hessian diagonal block size is 9 here: torch.sum() reduces the dim 2/3.\n",
        "                hutchinson_trace.append(tmp_output)\n",
        "        \n",
        "        return hutchinson_trace\n",
        "\n",
        "    def step(self, gradsH, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            gradsH: The gradient used to compute Hessian vector product.\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        # get the Hessian diagonal\n",
        "        hut_trace = self.get_trace(gradsH)\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for i, p in enumerate(group['params']):\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = deepcopy(gradsH[i].data)\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of Hessian diagonal square values\n",
        "                    state['exp_hessian_diag_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg, exp_hessian_diag_sq = state['exp_avg'], state['exp_hessian_diag_sq']\n",
        "\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_hessian_diag_sq.mul_(beta2).addcmul_(\n",
        "                    1 - beta2, hut_trace[i], hut_trace[i])\n",
        "\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "\n",
        "                # make the square root, and the Hessian power\n",
        "                k = group['hessian_power']\n",
        "                denom = (\n",
        "                    (exp_hessian_diag_sq.sqrt() ** k) /\n",
        "                    math.sqrt(bias_correction2) ** k).add_(\n",
        "                    group['eps'])\n",
        "\n",
        "                # make update\n",
        "                p.data = p.data - \\\n",
        "                    group['lr'] * (exp_avg / bias_correction1 / denom + group['weight_decay'] * p.data)\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "KjO5vjz4LDub"
      },
      "id": "KjO5vjz4LDub",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/model.py\n",
        "!wget https://raw.githubusercontent.com/artfin/PES-Fitting-MSA/master/dataset.py\n",
        "\n",
        "from dataset import PolyDataset\n",
        "from dataset import HTOCM\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "RgUGE1aQLpFn"
      },
      "id": "RgUGE1aQLpFn",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wdir = './H2-H2O'\n",
        "order = '3'\n",
        "symmetry = '2 2 1'\n",
        "dataset = PolyDataset(wdir=wdir, config_fname='points.dat', order=order, symmetry=symmetry)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzkUUlJvLkF6",
        "outputId": "abd6a267-7d72-4a79-daf7-2d5dc4868cbd"
      },
      "id": "lzkUUlJvLkF6",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] working directory: ./H2-H2O\n",
            "[INFO] configuration file: ./H2-H2O/points.dat\n",
            "[INFO] loading configurations...\n",
            "[INFO] detected NATOMS = 5\n",
            "[INFO] detected NCONFIGS = 44623\n",
            "[INFO] preparing the coordinates..\n",
            "[INFO] Done.\n",
            "[INFO] detected NMON  = 39\n",
            "[INFO] detected NPOLY = 102\n",
            "[INFO] Preparing the polynomials...\n",
            "[INFO] Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = np.random.permutation(len(dataset))\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size  = len(dataset) - train_size\n",
        "logging.info(\"Train size = {}\".format(train_size))\n",
        "logging.info(\"Test size  = {}\".format(test_size))\n",
        "\n",
        "train_ids = ids[:train_size]\n",
        "test_ids  = ids[train_size:]\n",
        "\n",
        "X, y             = dataset.X, dataset.y\n",
        "X_train, y_train = X[train_ids], y[train_ids]\n",
        "X_test, y_test   = X[test_ids], y[test_ids]\n",
        "\n",
        "# scaling\n",
        "mean = X_train.mean(axis=0)\n",
        "std  = X_train.std(axis=0)\n",
        "# first polynomial is a constant => std = 0.0\n",
        "std[0] = 1.0\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test  = (X_test - mean) / std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSq8O0jkKDve",
        "outputId": "3da36176-2b51-4df5-85d0-7415c8ac101c"
      },
      "id": "WSq8O0jkKDve",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] Train size = 35698\n",
            "[INFO] Test size  = 8925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jun Li, Bin Jiang, and Hua Guo\n",
        "# J. Chem. Phys. 139, 204103 (2013); https://doi.org/10.1063/1.4832697\n",
        "# Suggest using Tanh activation function and 2 hidden layers\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class FCNet(nn.Module):\n",
        "    def __init__(self, NPOLY, n_layers=2, n_neurons=20, activation=nn.Tanh, init_form=\"uniform\"):\n",
        "        super().__init__()\n",
        "\n",
        "        self.NPOLY      = NPOLY\n",
        "        self.n_layers   = n_layers\n",
        "        self.activation = activation()\n",
        "        self.init_form  = init_form\n",
        "\n",
        "        layers = [\n",
        "            nn.Linear(self.NPOLY, n_neurons), self.activation,\n",
        "            nn.Linear(n_neurons, n_neurons),         self.activation,\n",
        "            nn.Linear(n_neurons, 1)\n",
        "        ]\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        # if isinstance(self.activation, nn.ReLU):\n",
        "        #     self.init_kaiming(activation_str=\"relu\")\n",
        "        # elif isinstance(self.activation, nn.Tanh):\n",
        "        #     self.init_xavier(activation_str=\"tanh\")\n",
        "        # elif isinstance(self.activation, nn.Sigmoid):\n",
        "        #     self.init_xavier(activation_str=\"sigmoid\")\n",
        "        # else:\n",
        "        #     raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "    def init_xavier(self, activation_str):\n",
        "        sigmoid_gain = nn.init.calculate_gain(activation_str)\n",
        "        for child in self.layers.children():\n",
        "            if isinstance(child, nn.Linear):\n",
        "                for _ in range(0, self.n_layers - 1):\n",
        "                    if self.init_form == \"normal\":\n",
        "                        nn.init.xavir_normal_(child.weight, gain=sigmoid_gain)\n",
        "                        if child.bias is not None:\n",
        "                            nn.init.zeros_(child.bias)\n",
        "                    elif self.init_form == \"uniform\":\n",
        "                        nn.init.xavier_uniform_(child.weight, gain=sigmoid_gain)\n",
        "                        if child.bias is not None:\n",
        "                            nn.init.zeros_(child.bias)\n",
        "\n",
        "                    else:\n",
        "                        raise NotImplementedError()\n",
        "\n",
        "    def init_kaiming(self, activation_str):\n",
        "        raise NotImplementedError()"
      ],
      "metadata": {
        "id": "UbhvG3y9X4jI"
      },
      "id": "UbhvG3y9X4jI",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_params(model):\n",
        "    nparams = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        params = torch.tensor(param.size())\n",
        "        nparams += torch.prod(params, 0)\n",
        "\n",
        "    return nparams"
      ],
      "metadata": {
        "id": "YpmBbeJhL9N7"
      },
      "id": "YpmBbeJhL9N7",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train, y_train, X_test, y_test, opt_type='adam', epochs=100, device='cpu'):\n",
        "    # in case the structure of the model changes\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    metric = nn.MSELoss().to(device)\n",
        "\n",
        "    if opt_type == 'lbfgs':\n",
        "        # Standard version from torch.optim\n",
        "        optimizer = optim.LBFGS(model.parameters(), lr=1.5, max_iter=20, max_eval=None, tolerance_grad=1e-14, tolerance_change=1e-14, history_size=10)\n",
        "    elif opt_type == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0)\n",
        "    elif opt_type == 'adahessian':\n",
        "        logging.info('Adahessian optimizer is chosen')\n",
        "        optimizer = Adahessian(model.parameters(), lr=1.0, betas=(0.9, 0.999),\n",
        "                               eps=1e-4, weight_decay=0.0, hessian_power=1.0)\n",
        "    elif opt_type == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
        "    else:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    dprint = epochs // 20\n",
        "  \n",
        "    X_train.to(device)\n",
        "    y_train.to(device)\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_train)\n",
        "\n",
        "        loss = torch.sqrt(metric(y_pred, y_train))\n",
        "        loss.backward(create_graph=True)\n",
        "        \n",
        "        _, gradsH = get_params_grad(model)\n",
        "\n",
        "        optimizer.step(gradsH)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(X_test)\n",
        "            test_loss = metric(y_pred, y_test)\n",
        "            test_rmse = np.sqrt(test_loss.item())\n",
        "\n",
        "        if epoch % dprint == 0:\n",
        "            print(\"Epoch: {}; train rmse: {:.10f}; test rmse: {:.10f}\".format(\n",
        "                epoch, loss * HTOCM, test_rmse * HTOCM\n",
        "            ))"
      ],
      "metadata": {
        "id": "C9gVtyXgKUlH"
      },
      "id": "C9gVtyXgKUlH",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers   = 2\n",
        "activation = nn.Tanh\n",
        "init_form  = \"uniform\"\n",
        "logging.info(\"Creating a fully connected neural network:\")\n",
        "logging.info(\"    n_layers   = {}\".format(n_layers))\n",
        "logging.info(\"    activation = {}\".format(activation))\n",
        "logging.info(\"    init_form  = {}\".format(init_form))\n",
        "\n",
        "model = FCNet(NPOLY=dataset.NPOLY, n_layers=n_layers, activation=activation, init_form=init_form)\n",
        "model.double() # use double precision for model parameters \n",
        "\n",
        "nparams = count_params(model)\n",
        "logging.info(\"number of parameters: {}\".format(nparams))\n",
        "\n",
        "train(model, X_train, y_train, X_test, y_test, opt_type='adahessian', epochs=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h0IuBOdQK49",
        "outputId": "10f4e9a2-c9cf-46dd-c060-07c854966e5c"
      },
      "id": "5h0IuBOdQK49",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] Creating a fully connected neural network:\n",
            "[INFO]     n_layers   = 2\n",
            "[INFO]     activation = <class 'torch.nn.modules.activation.Tanh'>\n",
            "[INFO]     init_form  = uniform\n",
            "[INFO] number of parameters: 2501\n",
            "[INFO] Adahessian optimizer is chosen\n",
            "  0%|          | 3/10000 [00:00<16:28, 10.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0; train rmse: 283285.4689068816; test rmse: 482552.5886767792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 503/10000 [00:45<14:33, 10.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 500; train rmse: 920.6484789673; test rmse: 2548.4132577104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1002/10000 [01:28<12:18, 12.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1000; train rmse: 847.7163912667; test rmse: 1925.2357614978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 1502/10000 [02:10<12:18, 11.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1500; train rmse: 796.1160599622; test rmse: 1348.6904450591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2002/10000 [02:53<11:33, 11.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2000; train rmse: 760.3389747544; test rmse: 1356.1711874091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 2502/10000 [03:37<10:33, 11.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2500; train rmse: 736.2867845886; test rmse: 1391.3887762613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3002/10000 [04:20<09:49, 11.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3000; train rmse: 711.9360681942; test rmse: 1297.0072184479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 3502/10000 [05:03<08:38, 12.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3500; train rmse: 694.0589292411; test rmse: 1152.2766179363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4002/10000 [05:46<09:27, 10.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4000; train rmse: 661.4228301516; test rmse: 1069.2637345660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 4502/10000 [06:28<07:35, 12.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4500; train rmse: 637.4407654180; test rmse: 1151.9414729881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5002/10000 [07:11<06:44, 12.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5000; train rmse: 626.4905736148; test rmse: 1328.9514843605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 5502/10000 [07:54<06:03, 12.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5500; train rmse: 619.0504364721; test rmse: 1337.1049323673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6002/10000 [08:36<05:41, 11.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6000; train rmse: 613.3405219207; test rmse: 1406.2978174135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 6502/10000 [09:19<04:58, 11.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6500; train rmse: 607.1643681201; test rmse: 1392.4707436667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7003/10000 [10:04<04:13, 11.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7000; train rmse: 585.6861569861; test rmse: 1301.6261526454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 7503/10000 [10:46<03:22, 12.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7500; train rmse: 563.1363286252; test rmse: 1262.8427999261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8003/10000 [11:27<02:42, 12.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8000; train rmse: 552.5781559474; test rmse: 1407.9162173276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 8503/10000 [12:08<02:07, 11.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8500; train rmse: 546.6126801425; test rmse: 1359.5262011620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9003/10000 [12:51<01:24, 11.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9000; train rmse: 542.3913803167; test rmse: 1223.2910132473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 9503/10000 [13:34<00:41, 11.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9500; train rmse: 539.0658222682; test rmse: 1055.0151993697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [14:17<00:00, 11.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers   = 3\n",
        "activation = nn.Tanh\n",
        "init_form  = \"uniform\"\n",
        "logging.info(\"Creating a fully connected neural network:\")\n",
        "logging.info(\"    n_layers   = {}\".format(n_layers))\n",
        "logging.info(\"    activation = {}\".format(activation))\n",
        "logging.info(\"    init_form  = {}\".format(init_form))\n",
        "\n",
        "model = FCNet(NPOLY=dataset.NPOLY, n_layers=n_layers, activation=activation, init_form=init_form)\n",
        "model.double() # use double precision for model parameters \n",
        "\n",
        "nparams = count_params(model)\n",
        "logging.info(\"number of parameters: {}\".format(nparams))\n",
        "\n",
        "train(model, X_train, y_train, X_test, y_test, opt_type='adahessian', epochs=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgsQA_V5Sqpk",
        "outputId": "5b538f93-f2d2-4531-bca9-8af67ae38ba2"
      },
      "id": "GgsQA_V5Sqpk",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] Creating a fully connected neural network:\n",
            "[INFO]     n_layers   = 3\n",
            "[INFO]     activation = <class 'torch.nn.modules.activation.Tanh'>\n",
            "[INFO]     init_form  = uniform\n",
            "[INFO] number of parameters: 2501\n",
            "[INFO] Adahessian optimizer is chosen\n",
            "  0%|          | 2/10000 [00:00<14:47, 11.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0; train rmse: 40359.0259279137; test rmse: 1028075.2092588076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 502/10000 [00:42<13:40, 11.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 500; train rmse: 1424.7898992950; test rmse: 1961.0768309460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1002/10000 [01:25<12:54, 11.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1000; train rmse: 934.1398151534; test rmse: 1479.8861898890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 1502/10000 [02:09<12:42, 11.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1500; train rmse: 742.8580468206; test rmse: 1232.0997289684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2002/10000 [02:53<11:31, 11.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2000; train rmse: 639.4889761031; test rmse: 1075.2949714044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 2502/10000 [03:38<11:31, 10.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2500; train rmse: 578.6634692790; test rmse: 1029.1629945469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3002/10000 [04:22<10:45, 10.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3000; train rmse: 538.3884663207; test rmse: 1031.8614910105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 3502/10000 [05:05<08:57, 12.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3500; train rmse: 510.2804192354; test rmse: 1049.5858630059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4002/10000 [05:49<09:01, 11.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4000; train rmse: 490.5878881229; test rmse: 1068.8283795168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 4502/10000 [06:32<07:35, 12.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4500; train rmse: 472.6473896440; test rmse: 1074.9992482328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5002/10000 [07:15<07:08, 11.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5000; train rmse: 460.5439005400; test rmse: 1080.8219823764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 5502/10000 [07:58<06:18, 11.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5500; train rmse: 447.0478055959; test rmse: 1096.1719092662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6002/10000 [08:40<05:38, 11.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6000; train rmse: 437.1532285479; test rmse: 1108.8055002785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 6502/10000 [09:24<04:47, 12.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6500; train rmse: 429.7581496811; test rmse: 1085.4641457776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7002/10000 [10:06<04:28, 11.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7000; train rmse: 423.4262349188; test rmse: 1083.9310780640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 7502/10000 [10:49<03:33, 11.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7500; train rmse: 418.0086627241; test rmse: 1094.8349802831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8002/10000 [11:33<02:52, 11.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8000; train rmse: 413.2811855539; test rmse: 1106.1242918588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 8502/10000 [12:16<02:10, 11.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8500; train rmse: 408.2044335057; test rmse: 1129.9208695780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9002/10000 [12:58<01:24, 11.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9000; train rmse: 401.1724953494; test rmse: 1135.1621155927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 9502/10000 [13:42<00:42, 11.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9500; train rmse: 397.2644096662; test rmse: 1133.2381568767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [14:25<00:00, 11.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers   = 3\n",
        "activation = nn.Tanh\n",
        "init_form  = \"uniform\"\n",
        "logging.info(\"Creating a fully connected neural network:\")\n",
        "logging.info(\"    n_layers   = {}\".format(n_layers))\n",
        "logging.info(\"    activation = {}\".format(activation))\n",
        "logging.info(\"    init_form  = {}\".format(init_form))\n",
        "\n",
        "model = FCNet(NPOLY=dataset.NPOLY, n_layers=n_layers, n_neurons=25, activation=activation, init_form=init_form)\n",
        "model.double() # use double precision for model parameters \n",
        "\n",
        "nparams = count_params(model)\n",
        "logging.info(\"number of parameters: {}\".format(nparams))\n",
        "\n",
        "train(model, X_train, y_train, X_test, y_test, opt_type='adahessian', epochs=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMqyXZyrcCSo",
        "outputId": "3c5fd521-6468-468a-aac6-7045089f666e"
      },
      "id": "XMqyXZyrcCSo",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] Creating a fully connected neural network:\n",
            "[INFO]     n_layers   = 3\n",
            "[INFO]     activation = <class 'torch.nn.modules.activation.Tanh'>\n",
            "[INFO]     init_form  = uniform\n",
            "[INFO] number of parameters: 3251\n",
            "[INFO] Adahessian optimizer is chosen\n",
            "  0%|          | 2/10000 [00:00<21:02,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0; train rmse: 64640.6955303114; test rmse: 299222.7980895268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 502/10000 [00:59<23:06,  6.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 500; train rmse: 1031.6693259233; test rmse: 2366.4363387110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1002/10000 [01:58<18:12,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1000; train rmse: 519.2097193844; test rmse: 1978.3795494326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 1502/10000 [02:56<17:11,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1500; train rmse: 450.5137172999; test rmse: 1859.8487154899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2002/10000 [03:55<14:46,  9.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2000; train rmse: 406.0129349953; test rmse: 1706.7958665047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 2502/10000 [04:55<14:40,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2500; train rmse: 367.8314343875; test rmse: 1550.2974797075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 3002/10000 [05:54<13:17,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3000; train rmse: 340.0653322186; test rmse: 1500.3303072694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 3502/10000 [06:52<12:01,  9.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3500; train rmse: 321.9743004880; test rmse: 1504.0180426037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 4002/10000 [07:50<10:59,  9.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4000; train rmse: 309.3893868393; test rmse: 1508.7230269573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 4502/10000 [08:47<10:24,  8.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4500; train rmse: 299.7910648496; test rmse: 1501.4203512830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5002/10000 [09:45<09:20,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5000; train rmse: 292.0671695973; test rmse: 1493.6699980677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 5502/10000 [10:43<09:19,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5500; train rmse: 285.0004412463; test rmse: 1484.2221845724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 6002/10000 [11:42<07:57,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6000; train rmse: 279.5594689150; test rmse: 1485.4625321690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 6502/10000 [12:38<07:00,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6500; train rmse: 274.5537685082; test rmse: 1498.2922103070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 7002/10000 [13:36<05:52,  8.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7000; train rmse: 269.6865801193; test rmse: 1527.4075765714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 7502/10000 [14:33<04:37,  9.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7500; train rmse: 264.1025095999; test rmse: 1571.0795499527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 8002/10000 [15:30<03:44,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8000; train rmse: 257.6659144161; test rmse: 1606.8843647146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 8502/10000 [16:26<02:40,  9.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8500; train rmse: 251.4978896710; test rmse: 1643.1589265392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 9002/10000 [17:21<01:48,  9.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9000; train rmse: 247.3765115994; test rmse: 1693.4420061411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 9502/10000 [18:17<00:55,  9.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9500; train rmse: 243.6326660844; test rmse: 1738.0347462144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [19:12<00:00,  8.67it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "collab|pip-nn-pes.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}